<!DOCTYPE html>
<html class="fontawesome-i2svg-active fontawesome-i2svg-complete">

<head>
  <meta charset="utf-8">
  <meta name="description" content="A Multimodal, Multigenre, and Multipurpose Audio-Visual Academic Lecture Dataset">
  <meta name="keywords" content="Audio-Visual Academic Lecture Dataset">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title> ReflectTool: Towards Reflection-Aware Tool-Augmented Clinical Agents</title>

  <link rel="icon"
    href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üéì</text></svg>">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/font-awesome.all.css" type="text/css">
  <link rel="stylesheet" href="./static/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="static/js/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
</head>

<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title is-bold">
              <span style="vertical-align: middle">üéìReflectTool</span>
            </h1>
            <h2 class="subtitle is-3 publication-subtitle">
              <b>T</b>owards <b>R</b>eflection-<b>A</b>ware <b>T</b>ool-<b>A</b>ugmented <b>C</b>linical <b>A</b>gents
              Lecture Dataset
              <!-- <br> -->
              <!-- with GPT-4V, Bard, and Other Large Multimodal Models -->
            </h2>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=ErjimggAAAAJ">Yusheng Liao</a><sup
                  style="color:#2878B5;">1,</sup><sup style="color:#43a343;">3</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=slwTiOUAAAAJ">Shuyang Jiang</a><sup
                  style="color:#b12323;">2,</sup><sup style="color:#43a343;">3</sup>,
              </span>
              <span class="author-block">
                <a href="https://yuwangsjtu.github.io/">Yu Wang</a><sup style="color:#2878B5;">1,</sup><sup
                  style="color:#43a343;">3‚úâÔ∏è</sup>,
              </span>
              <span class="author-block">
                <a href="https://cmic.sjtu.edu.cn/wangyanfeng/">Yanfeng Wang</a><sup style="color:#2878B5;">1,</sup><sup
                  style="color:#43a343;">3</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup style="color:#2878B5;">1</sup>Shanghai JiaoTong University</span><br>
              <span class="author-block"><sup style="color:#b12323;">2</sup>Fudan University</span><br>
              <span class="author-block"><sup style="color:#43a343;">3</sup>Shanghai Artifical Intelligence Laboratory</span>
              <!-- <span class="author-block"><sup></sup><sub></sub><b style="color:#f41c1c;">ACL 2024 Main Conference</b></span> -->
            </div>


            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2410.17657"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <!-- Github Link. -->
                <span class="link-block">
                  <a href="https://github.com/BlueZeros/ReflecTool"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Github</span>
                  </a>
                </span>
                <!-- Download Link. -->
                <span class="link-block">
                  <a href="https://huggingface.co/datasets/BlueZeros/ClinicalAgentBench"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <!-- <i class="far fa-images"></i> -->
                      <p style="font-size:18px">üì•</p>
                      <!-- üîó -->
                    </span>
                    <span>Benchmarks</span>
                  </a>
                </span>
                <!-- Demo Link. -->
                <!-- <span class="link-block">
                  <a href="https://github.com/Jack-ZC8/M3AV-dataset/tree/main/demo"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <p style="font-size:18px">üíé</p>
                    </span>
                    <span>Demo</span>
                  </a>
                </span> -->
                <!-- Benchmark Link. -->
                <span class="link-block">
                  <a href="https://github.com/BlueZeros/ReflecTool#-leaderboard"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <p style="font-size:18px">üèÜ</p>
                    </span>
                    <span>LeaderBoard</span>
                  </a>
                </span>
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="section">
    <div class="container">
      <h2 class="title is-3 has-text-centered">Abstract</h2>
      <div class="columns is-centered has-text-justified">
        <div class="column is-three-fifths">
            <p>
              Large Language Models (LLMs) have shown promising potential in the medical domain, assisting with tasks like clinical note generation and patient communication. However, current LLMs are limited to text-based communication, hindering their ability to interact with diverse forms of information in clinical environments. Despite clinical agents succeeding in diverse signal interaction, they are oriented to a single clinical scenario and hence fail for broader applications. To evaluate clinical agents holistically, we propose <b>ClinicalAgent Bench (CAB)</b>, a comprehensive medical agent benchmark consisting of <b>18 tasks across five key realistic clinical dimensions.</b> 
            </p>
            <br>
            <p>  
              Building on this, we introduce <b>ReflectTool</b>, a novel framework that excels at utilizing domain-specific tools within two stages. The first <b>optimization stage</b> progressively enlarges a long-term memory by saving successful solving processes and tool-wise experience of agents in a tiny pre-defined training set. In the following <b>inference stage</b>, ReflectTool can search for supportive successful demonstrations from already built long-term memory to guide the tool selection strategy, and a verifier improves the tool usage according to the tool-wise experience with two verification methods--<b>Iterative Refinement</b> and <b>Candidate Selection</b>.
            </p>
            <br>
            <p>
              Extensive experiments on ClinicalAgent Benchmark demonstrate that ReflectTool surpasses the pure LLMs with more than <b>10</b> points and the well-established agent-based methods with <b>3</b> points, highlighting its adaptability and effectiveness in solving complex clinical tasks.
            </p>
            <!-- <p>
              In this paper, we propose a novel multimodal, multigenre, and multipurpose audio-visual academic lecture
              dataset (üéìM<sup>3</sup>AV), which has almost 367 hours of videos from five sources covering computer science,
              mathematics, and medical and biology topics. With <b>high-quality human annotations of the slide text and
                spoken words</b>, in particular <b>high-valued name entities</b>, the dataset can be used for <b>multiple
                audio-visual recognition and understanding tasks</b>.
            </p>
            <p>
              Evaluations performed on <b>contextual speech recognition, speech synthesis, and slide and script generation
                tasks</b> demonstrate that the diversity of üéìM<sup>3</sup>AV makes it a challenging dataset.
            </p> -->
        </div>
      </div>
    </div>
  </section>

  <!-- <section class="hero is-light is-small">
    <div class="hero-body has-text-centered">
      <h1 class="title is-1 mmmu">üéìM<sup>3</sup>AV Dataset</h1>
    </div>
  </section> -->

  <section class="hero is-light is-small">
    <div class="hero-body has-text-centered">
      <h1 class="title is-2 mmmu">ClinicalAgent Bench</h1>
    </div>
  </section>

  <section class="section">
    <div class="container">
      <h2 class="title is-3 has-text-centered">Overview</h2>
      <div class="columns is-centered has-text-justified">
        <div class="column is-three-fifths">
          Despite clinical agents succeeding in diverse signal interaction, they are oriented to a single clinical scenario and hence fail for broader applications. To evaluate clinical agents holistically, we propose ClinicalAgent Bench, a comprehensive medical agent benchmark consisting of <b>18 tasks across five key realistic clinical dimensions</b>.
        </div>
      </div>
      <div class="columns is-centered">
        <div class="column is-three-fifths">
          <img src="./static/images/agentbench_case.png" alt=""/>
          <p class="has-text-centered is-size-6">
            Figure 1: The overview of ClinicalAgent Bench.
          </p>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container">
      <h2 class="title is-3 has-text-centered">Data Statistics</h2>
      <div class="columns is-centered has-text-justified">
        <div class="column is-three-fifths">
          The statistics of the ClinicalAgent Bench dataset is shown below. We investigate existing public medical datasets and divide them according to the ability requirement of the agents. The ClinicalAgent Bench contains 18 tasks across five capacity dimensions, including <b>Knowledge&Reasoning</b>, <b>MultiModal</b>, <b>Numerical Analysis</b>, <b>Data Understanding</b>, and <b>Trustworthiness</b>. 
          All the data examples were divided into two subsets: test and optimization:
          <li>
            <b>test</b>: 14879 samples for standard evaluations, with average 826 samples for each dataset.
          </li>
          <li>
            <b>optimization</b>: we also provide 200 samples of each dataset for agent optimization.
          </li>
        </div>
      </div>
      <div class="columns is-centered">
        <div class="column is-half">
          <img src="./static/images/agentbench_overview.png" alt="" />
          <p class="has-text-centered is-size-6">
            Figure 2: Data Statistics of ClinicalAgent Bench.
          </p>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container">
      <h2 class="title is-3 has-text-centered">Clinical ToolBox</h2>
      <div class="columns is-centered has-text-justified">
        <div class="column is-three-fifths">
          Based on the ClinicalAgent Bench, we develop a toolbox that contains <b>17 types of tools</b> to enable agents to handle diverse tasks.
        </div>
      </div>
      <div class="columns is-centered has-text-justified">
        <div class="column is-three-fifths">
          <img src="static/images/clinical_tools.png" alt="" />
          <p class="has-text-centered is-size-6">
            Table 1: The description of the tools in the clinical toolbox. The column of Input shows the tools‚Äô input format,
            which indicates the form of the information that the tool can leverage.
          </p>
        </div>
      </div>
    </div>
  </section>


  <section class="hero is-light is-small">
    <div class="hero-body has-text-centered">
      <h1 class="title is-2 mmmu">Method: ReflecTool</h1>
    </div>
  </section>

  <section class="section">
    <div class="container">
      <div class="columns is-centered has-text-justified">
        <div class="column is-three-fifths">
          We introduce <b>ReflectTool</b>, a novel framework that excels at utilizing domain-specific tools within two stages. ReflectTool can search for supportive successful demonstrations from already built long-term memory to guide the tool selection strategy, and a verifier improves the tool usage according to the tool-wise experience with two verification methods--<b>Iterative Refinement</b> and <b>Candidate Selection</b>.
        </div>
      </div>
      <div class="columns is-centered has-text-justified">
        <div class="column is-three-fifths">
          <img src="./static/images/method_overview.png" alt="" />
          <p class="has-text-centered is-size-6">
            Figure 3: Overview of the ReflecTool.
          </p>
        </div>
      </div>
    </div>
  </section>

  <section class="hero is-light is-small">
    <div class="hero-body has-text-centered">
      <h1 class="title is-2 mmmu">Performance & Analysis</h1>
    </div>
  </section>


  <section class="section">
    <div class="container">
      <h2 class="title is-3 has-text-centered">Performance on ClinicalAgent Bench</h2>
      <div class="columns is-centered has-text-justified">
        <div class="column is-three-fifths">
          
        </div>
      </div>
      <div class="columns is-centered has-text-justified">
        <div class="column is-three-fifths">
          <img src="./static/images/cab_performance.png" alt="" />
          <p class="has-text-centered is-size-6">
            Table 2: Experimental results of four types of models on Clinical Agent Bench. The ‚ÄòCOT‚Äô method indicates the
            agent runs without the pre-built tools. ‚Äò*‚Äô indicates the models use 4-bit GPTQ quantization. ‚Äò-‚Äô means the model is
            not capable of solving such a task. The best results of each type of task are <b>Bold</b>.
          </p>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container">
      <h2 class="title is-3 has-text-centered">Ablation Experiments</h2>
      <div class="columns is-centered has-text-justified">
        <div class="column is-three-fifths">
          
        </div>
      </div>
      <div class="columns is-centered has-text-justified">
        <div class="column is-three-fifths">
          <img src="./static/images/ablation.png" alt="" />
          <p class="has-text-centered is-size-6">
            Table 3: Ablation results of Refinement and Selection verification methods. All the experiments are conducted on
            Qwen2-72B. The modules of the REFLECTOOL contain Reflective Memory and Tool-wise Reflection.
          </p>
        </div>
      </div>
      </div>
  </section>

  <section class="section">
    <div class="container">
      <h2 class="title is-3 has-text-centered">Analysis</h2>
      <div class="columns is-centered has-text-justified">
        <div class="column is-three-fifths">
          
        </div>
      </div>
      <div class="columns is-centered has-text-justified">
        <div class="column is-one-fifths">
          <img src="./static/images/optimization_step.png" alt="" />
          <p class="has-text-centered is-size-6">
            Figure 4: Impact of the verification size on Iterative Refinement and Candidate Selection methods.
          </p>
        </div>
        <div class="column is-three-fifths">
          <img src="./static/images/verification_size.png" alt="" />
          <p class="has-text-centered is-size-6">
            Figure 5: Impact of the verification size on Iterative Refinement and Candidate Selection methods.
          </p>
        </div>
      </div>
    </div>
  </section>

  <section class="hero is-light is-small">
    <div class="hero-body has-text-centered">
      <h1 class="title is-1 mmmu">Conclusion</h1>
    </div>
  </section>


  <section class="section">
    <div class="container">
      <div class="columns is-centered has-text-justified">
        <div class="column is-half">
          <p>
            In this paper, we introduce <b>ClinicalAgent Bench</b>, a holistic benchmark for clinical agents comprising 18 tasks across five key dimensions. Building upon it, we propose <b>ReflecTool</b>, a reflection-aware tool-augmented framework that optimizes tool utilization through long-term memory and tool-wise verification. To adaptively improve agent performance given varying backbones, we adopt Iterative Refinement and Candidate Selection to verify actions. Empirical results show that <b>ReflecTool</b> outperforms existing clinical agents, demonstrating superior adaptability and efficacy in real-world healthcare scenarios.
          </p>
        </div>
      </div>
    </div>
  </section>


  <!-- @PAN TODO: bibtex -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title is-3 has-text-centered">BibTeX</h2>
      <pre><code>
        @misc{liao2024reflectoolreflectionawaretoolaugmentedclinical,
          title={ReflecTool: Towards Reflection-Aware Tool-Augmented Clinical Agents}, 
          author={Yusheng Liao and Shuyang Jiang and Yanfeng Wang and Yu Wang},
          year={2024},
          eprint={2410.17657},
          archivePrefix={arXiv},
          primaryClass={cs.CL},
          url={https://arxiv.org/abs/2410.17657}, 
        }
      </code></pre>
    </div>
  </section>

  <footer class="footer">
    <!-- <div class="container"> -->
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is adapted from <a href="https://nerfies.github.io/">Nerfies</a> and <a
              href="https://mathvista.github.io/">MathVista</a>, licensed under a <a rel="license"
              href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
    <!-- </div> -->
  </footer>

</body>

</html>
